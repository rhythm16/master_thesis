% !TeX root = ../main.tex
%\raggedbottom

\chapter{Background}
\label{sec:bg}

\section{Overview of the ARM Architecture}
\label{sec:armarch}

%overview of the architecture, and include virtualization extension and VHE
Our work is based on the ARM architecture for its mass adoption in mobile
devices, and its rising popularity among major cloud providers
\cite{armaws, armgooglecloud}. Different from x86, the ARM architecture has a
larger general register count, fixed length instructions, and simpler
instructions. These properties stem from ARM's original Reduced Instruction
Set Computer (RISC) design. CPU privilege levels in ARM are referred as
\textit{Exception Levels} (EL), and there are four of them: EL0, EL1, EL2, EL3.
The larger the exception level number, the greater the privilege. EL0 is the
lowest privilege level designed for userspace software, the \code{svc} instruction
(supervisor call) can be issued is this EL to trap to EL1 for system call
service. EL1 is regularly used for running an OS kernel like the Linux kernel.
EL1 controls EL0/1 page tables to enable virtual memory for userspace and the
kernel space,
and sets up the exception vectors to handle EL0 and EL1 exceptions. EL1 can
also ask for EL2 service via the \code{hvc} instruction (hypervisor call). EL2
is designed for running a hypervisor. It is more privileged than EL1, software
EL2 is capable of setting various conditions for the hardware to trap to EL2 to
intervene the lower EL1 and EL0 execution. For example, it is capable of
redirecting all device interrupts to EL2's own exception vector to interpose
all interrupts. ARM also provides Nested Page Table (NPT) support in EL2. If
EL2 enables NPTs, the physical address that results from an EL0/1 page table walk
becomes the \textit{Intermediate Physical Address} (IPA), the IPA must then be
translated again by the additional set of page tables set up by the software in
EL2 to finally get the physical address used for memory access. The address
translation turns into a two stage process, firstly the EL0/1 virtual address
is translated into IPA by walking the EL0/1 page table controlled by the kernel
in EL1, after that it is translated again by walking the NPT. Thus, when a
hypervisor enables NPT, all guest kernels in EL1 only see its own virtual guest
physical address space. The hypervisor has full control over the physical
memory. Lastly, EL3 is the highest privilege level typically used for running
system firmware that initializes the hardware. The
\textit{Virtualization Host Extensions} (VHE) is an ARM architecture extension
added to support running an unmodified OS kernel designed for an EL1
environment directly in EL2. The extension is needed because
originally, EL2 differs from EL1 in a few ways. First, EL1 has two
\textit{Translation Table Base Registers} (TTBRs), while EL2 only has one. It
was designed like this because OS kernels running in EL1 need the extra base
register to separate user process address space and kernel address space, and
hypervisors normally do not host applications. Second, there is no
\textit{Address Space Identifiers} (ASIDs) support in EL2 for the same reason.
Third, the bit layout of some system registers and page table format in EL2 are
different from their EL1 counterparts.
%These limitations made it difficult for
%a kernel previously designed for an EL1 environment to run in EL2 without
%modifications.
%The ARM architecture was later extended with \textit{Virtualization Host Extensions} (VHE).
VHE addresses the problems above by adding another TTBR, ASID support, and
synchronized the bit layout of EL2 and EL1 system registers and the page table
formats. On hardware that support VHE, the Linux kernel can thus boot in both
EL1 and EL2.

\section{KVM ARM}

%split-mode virtualization, NVHE, VHE modes
KVM ARM was merged into the mainline Linux kernel version 3.9 \cite{kvmarmlwn}.
It was designed to support unmodified guest VMs by utilizing hardware
virtualization support introduced in \autoref{sec:armarch}. The authors
proposed \textit{split-mode virtualization} \cite{kvmarm}, allowing the KVM ARM
hypervisor to split its execution across CPU modes and be integrated into the
Linux kernel. Split-mode virtualization installs a small amount of code in EL2
called the \textit{lowvisor} when Linux initializes. The lowvisor is only
responsible for hypervisor tasks that can only be done in the more privileged
EL2, including running EL2 exception vectors and installing the addresses NPTs
in the \code{VTTBR\_EL2} register, which holds the NPT root pointer. Split-mode
virtualization has various advantages. Kernel features including memory
allocation, CPU scheduling can still be done in EL1, thus simplifying the
lowvisor, also the small lowvisor makes the addition of KVM ARM a less
intrusive change to the Linux codebase, increasing the possibility of it being
merged into the mainline kernel for its maintainability and ease of review.

Split-mode virtualization was proposed before the introduction of ARM VHE. With
VHE, the entire Linux kernel can be run in EL2, removing the need for KVM to
split its execution across CPU privilege levels. Before with split-mode
virtualization, the lowvisor must multiplex the EL1 context, or context switch
EL1 system registers when entering or exiting VMs, which leads to overhead. By
running Linux entirely in EL2, guest EL1 states do not have to be saved or
restored each time a VM enter or exit happens, reducing the overhead. KVM ARM
was then further developed to support both the new VHE feature (VHE mode),
while keeping the option for the original split-mode virtualization, or Non-VHE
(NVHE) mode.

\section{HypSec}

HypSec \cite{hypsec} is a new hypervisor design which uses microkernel principles to reduce
the trusted computing base of the hypervisor while protecting the
confidentiality and integrity of VM data. It is motivated by the fact that as
hypervisors become more complex, their ever-growing large codebases expose a
huge attack surface for adversaries. HypSec restructures the large monolithic
hypervisor into a minimized trusted core, the \textit{corevisor} and the
remaining large untrusted host, the \textit{hostvisor}.
The corevisor is reduced by separating access control from resource allocation.
The corevisor has full access to hardware resources to perform access control
to protect VM data.
On the other hand, I/O, interrupt virtualization and resource management such
as CPU scheduling, memory management, and device management are delegated to
the hostvisor, which can leverage a host OS.
The corevisor executes at a higher CPU privilege level than the hostvisor,
it deprivileges the hostvisor at a lower privileged level, ensuring
the untrusted host cannot disable or control privileged hardware features.
NPTs are enabled by the corevisor when running the hostvisor and VMs so that
they do not have direct access to physical memory.
The corevisor unmaps its own private memory pages from the respective NPTs,
making them inaccessible to VMs and the hostvisor. The corevisor unmaps a given
VM's memory pages from the hostvisor or other VMs' NPTs to isolate these pages.
NPTs for the hostvisor and VMs are allocated from the corevisor's memory pool,
to which the host and VMs have no access. Since VM and corevisor memory is
unmapped from the host NPT, a compromised hostvisor that accesses these memory
pages causes an NPT fault that traps to the corevisor. NPT faults are routed to
the corevisor itself, allowing it to reject invalid hostvisor memory accesses.
The work also used HypSec to retrofit KVM ARM's NVHE mode, showing how the
approach can support a widely used hypervisor while only incurring modest
performance overhead.

\section{SeKVM}
\label{sec:sekvmintro}

SeKVM \cite{sekvm} extended the work of HypSec and presented a secure and formally verified
Linux KVM hypervisor. While HypSec reduced the trusted computing base of the
hypervisor, potential bugs in the TCB can still nullify the guarantee of VM
data confidentiality and integrity. SeKVM builds on the design of HypSec and
further formally verified the hypervisor TCB. The work proposed
\textit{microverification},
where a large codebase such as KVM ARM, is restructured into a small core and a
set of untrusted services such that the security of the entire hypervisor can
be proven by verifying the small core alone. SeKVM retrofitted KVM ARM's NVHE
mode into the trusted \textit{KCore} and the set of untrusted services
\textit{KServ}.
To verify Kcore, \textit{security-preserving layers} are introduced to
modularize the verification process.
KCore's detailed C and assembly implementations are abstracted into higher-level
specifications with the help of the Coq proof assistant, the specifications are
then used to prove security properties that would be intractable to verify
directly on the implementation.

%Various previous work~\cite{lisosp21,zhang2011cloudvisor,zeyu20usenix,pkvm,fidelius-hpca18,sekvm}
%redesigned the hypervisor to protect VMs.

%Our work explores the possibility of rewriting a hypervisor TCB in Rust, we
%chose to base on the implementation of SeKVM \cite{sekvm}, because its artifact
%\cite{sekvm-artifact} is available, and also because it has a reduced TCB
%compared to mainline KVM, which minimizes the attack surface of the codebase,
%leading to a more secure hypervisor.

% mainline KVM -> HypSec -> SeKVM storyline
% HypSec design
% how did SeKVM come to be

%The original mainline KVM introduced
%SeKVM is a formally verified KVM hypervisor,
%it leveraged an earlier design~\cite{hypsec} to retrofit and secure KVM,
%it relies on a small TCB called \secore{} to protect VM confidentiality and
%integrity against an untrusted KVM host that encompasses the host Linux kernel
%integrated with KVM.

%To reduce the TCB,
%the design separates access control from resource allocation. \secore{}
%has full access to hardware resources to perform access control to
%protect VM data. SeKVM assumes VMs employ an end-to-end approach to
%encrypt I/O data. Since VMs already protect their I/O data, SeKVM
%focuses on protecting VM data in CPU and memory.
%The KVM host provides device drivers and complex virtualization features
%such as resource allocation, scheduling, and VM management. \secore{} is
%responsible for protecting VM data, ensuring VM CPU registers and memory
%allocated to the VM are inaccessible to the untrusted KVM host.
%
%\secore{} leverages hardware virtualization
%support to deprivilege the KVM host at a lower privileged level, ensuring
%the untrusted host cannot disable or control privileged hardware
%features. \secore{} enables the nested page tables (NPT) when running
%the KVM host and VMs so that they do not have direct access to physical
%memory.
%\secore{} unmaps its own private memory pages from the respective NPTs,
%making them inaccessible
%to VMs and the host. \secore{} unmaps a given VM's memory pages from
%the KVM host's or other VMs' NPTs to isolate these pages.
%\secore{} allocates NPTs for the KVM host
%and VMs from its memory pool, to which the host and VMs have no access.
%Since VM and \secore{} memory is unmapped from the host NPT, a
%compromised host that accesses these memory pages causes an NPT fault
%that traps to \secore{}. \secore{} routes NPT faults to itself,
%allowing it to reject invalid host memory accesses.
%
%SeKVM reuses the device drivers from the KVM host to manage
%I/O devices and provide I/O virtualization. An attacker from the host
%can control devices to perform Direct Memory Access (DMA) to
%read or write VM memory. To protect VM memory against such DMA
%attacks, SeKVM leverages IOMMU to restrict all devices'
%memory accesses. \secore{} allocates and manages IOMMU page
%tables from its private memory. \secore{} trap-and-emulates the
%KVM host's access to the IOMMU and manages the IOMMU page tables
%for each DMA-capable device.
%
%\secore{} runs in a higher privileged CPU mode than the host to
%interpose VM exits and interrupts, ensuring the host cannot compromise
%VM data.
%VM exit handling may require the KVM host's functionality. Before
%entering the host, \secore{} saves VM CPU registers from the
%hardware to its private memory then restores the host's CPU registers to
%the hardware; vice versa is done before entering the VM. An attacker has
%no access \secore{}'s private memory, and thus, the VM CPU registers.
%
%SeKVM leverages Arm's hardware Virtualization Extensions (VE) to
%simplify its implementation. \secore{} runs in the hypervisor mode
%(EL2) to control Arm VE features to deprivilege the KVM host in a less
%privileged kernel mode (EL1). \secore{} uses Arm's NPTs, stage 2
%page tables to enforce memory access control. Stage 2 page table
%translation only affects the software running in Arm's kernel and user
%(EL0) mode, but not software running in EL2. \secore{} employs an
%identity map in the KVM host's stage 2 page tables, translating each
%host machine's physical addresses (hPA) to an identical hPA. This
%allows SeKVM to reuse Linux's memory allocator to manage memory
%implicitly. Running in EL2 allows \secore{} to isolate itself
%from the host and VMs. First, running in EL2 isolates \secore{} in
%a separate address space from EL1 and EL0. Second, Arm provides banked
%system registers to EL1 and EL2. The host cannot access
%EL2 registers to disable \secore{}'s protection. For instance,
%the host cannot modify the register VTTBR\_EL2, which stores the base
%address of the stage 2 page tables. \secore{} exposes a set of
%required hypercalls~\cite{hypsec} for the host to request services
%that require EL2 privileges. For example, once the host schedules
%a virtual CPU, it makes a hypercall to \secore{} to context switch to
%the VM. \secore{} leverages Arm's IOMMU, the System Memory
%Management Unit (SMMU)~\cite{smmu-whitepaper}, to protect against
%DMA attacks.

%Unlike our work, none of them used
%Rust to secure their hypervisor implementation.
%\rustsec{} and SeKVM~\cite{sekvm} both leveraged an earlier design~\cite{hypsec}
%to retrofit and secure KVM, providing the same level of VM protection. SeKVM
%included a formally verified core to protect VMs against an untrusted host Linux
%kernel, while \rustsec{} relies on a Rust-based \rustcore{} to protect VMs.
%Formal verification of the concurrent C-based SeKVM core requires significant effort.
%The authors took two person-years to complete the correctness and security proofs.
%In contrast, our Rust-based implementation took less than one person-year while
%ensuring properties verified systems provide, including memory safety,
%data race, and deadlock freedom.

\section{The Rust Programming Language}
Rust is a relatively young programming language compared to C that aims to be
safe and fast.
It enables programs to be memory-safe without requiring programmers to manually
manage memory as in traditional languages (e.g. C/C++).
Different from other memory-safe languages such as Python or Go, Rust does not
employ garbage collection for managing memory. Instead, the concepts of
lifetimes, ownership, and borrowing rules are introduced to mandate the
programmer to follow specific rules.
Statically enforcing programming rules empowers Rust to perform comparably to
C. The rules are checked at compile time, eliminating the need for runtime
checks that incur overhead. Furthermore, these checks ensure adherence to the
specified rules, and if no violations are found, the code is directly
translated into machine instructions without any additional overhead or
alteration in behavior.
%Meaning the compiler can enforce memory safety of programs without performance penalties.
%Rust's compiler has complete control over the code that runs during runtime and can optimize it accordingly.
Additionally, Rust's safety rules ensure that no memory safety bugs will be
present when satisfied, and the compiler automatically checks and prevents any
violation of these rules.

\textbf{Ownership and Lifetimes.}
In Rust, each piece of data is said to be \textit{owned} by a single
variable, and it is automatically \textit{dropped} (freed) when the
variable's \textit{lifetime} ends. A variable's lifetime ends as the program
control flow exits the block in which the variable is declared.
In \autoref{lst:lifetime}, \code{y}'s lifetime starts at line 5 and ends at
line 7 as the block closes. Hence, the \code{println!} macro is unable to find
the value \code{y}, whose lifetime has already ended.
Ownership can be transferred or \textit{moved}. For example,
assigning the owning variable to a new variable moves the ownership of the
data to the new variable. And passing the variable into a function also moves
the data ownership into the function.
In both situations, the original variable returns to the uninitialized state,
and using it would result in a compilation error.

\begin{listing}[hbtp]
    \begin{minted}{rust}
// this code sample does *not* compile
{
  let x = 1;
  {            // create new scope
    let y;
    y = x;
  }            // y is dropped

  // compilation error, y's lifetime has ended
  println!("The value of 'y' is {}.", y);
}
    \end{minted}
    \caption{Rust lifetime example}
    \label{lst:lifetime}
    \vspace{-0.2cm}
\end{listing}

\textbf{Borrowing.}
Ownership lacks the flexibility of argument passing.
Rust addresses this by \textit{borrowing},
a mechanism that allows accessing data without gaining ownership.
A variable can borrow ownership from another variable to acquire a
\textit{reference} to the data. References can be divided into two categories,\textit{shared}
references and \textit{exclusive} references. The reference can only be read
and not modified with a shared reference. Nevertheless, multiple shared
references for a specific value can be held simultaneously.
On the other hand, exclusive references allow reading from and modifying the
value. However, having any other kind of reference active simultaneously for
that value is not permitted.

In summary, Rust's borrowing rule enforces \textit{aliasing xor mutability}
meaning there can be multiple shared references or a single exclusive
reference.
In \autoref{lst:borrowingrule}, line 6 would not compile because it tries to create
a mutable reference (\code{z}) to \code{x}, while \code{y} already borrowed
\code{x} immutably. \code{y}'s lifetime ends on line 8 as it gets used for the
last time; therefore \code{z} can be created on line 10 and used on line 11.
However, if line 13 is uncommented, \code{y}'s lifetime would be extended to
line 13, making the creation of \code{z} on line 10 break the borrowing rules.

\begin{listing}[hbtp]
    \begin{minted}{rust}
{
  let mut x = vec![1, 2, 3];
  let y = &x; // immutable borrow of x

  // this line would fail to compile because x is already borrowed immutably by y
  /* let z = &mut x; */

  println!("x = {:?}", x); // This line works
  println!("y = {:?}", y); // This line works

  let z = &mut x; // mutable borrow of x
  z.push(4);

  // this line would fail to compile because x is borrowed mutably by z
  /* println!("y = {:?}", y); */
}
    \end{minted}
    \caption{Rust enforces \textit{aliasing xor mutability}}
    \label{lst:borrowingrule}
    \vspace{-0.2cm}
\end{listing}

\textbf{unsafe Rust.}
Rust's safety checks are sometimes too restrictive regarding tasks like
low-level hardware access or special optimizations. These operations are
inherently unsafe and hence impossible to follow the rules mandated by Rust.
However, they are still necessary for low-level software such as
hypervisors. To provide flexibility for these operations, Rust allows
parts of the program to opt out of its safety checks via the \textit{unsafe}
keyword. Traits, functions, and code blocks can be marked as unsafe to disable
the checks that the compiler would normally enforce. However, using unsafe code
also means that the responsibility for ensuring memory safety is shifted from
the compiler to the programmer. Therefore, it is crucial to exercise
caution when using unsafe code to avoid introducing bugs or security
vulnerabilities.

\textbf{Interior unsafe.}
While most low-level code is written in unsafe code, Rust introduces
the concept of \textit{interior unsafe}~\cite{ruststudy}. A function is considered
interior unsafe if it exposes a safe interface but contains unsafe blocks
in implementation. This allows unsafe operations to be encapsulated
into safe abstractions. For instance, in
\autoref{lst:interiorunsafe}, Rust's \code{replace} function can be
called by safe Rust, but it is implemented using unsafe raw pointer operations.
At line 6, \code{ptr::read} is used to copy a bit-wise value from \code{dest}
into \code{result} without moving it, and at line 7, \code{ptr::write} overwrites
the memory location pointed to by \code{dest} with the given value \code{src}
without reading or dropping the old value. Lastly, at line 8, \code{result} is
returned to the function's caller.

\begin{listing}[hbtp]
    \begin{minted}{rust}
pub const fn replace<T>(dest: &mut T, src: T) -> T {
  // SAFETY: We read from `dest` but directly write `src` into it afterward,
  // such that the old value is not duplicated. Nothing is dropped and
  // nothing here can panic.
  unsafe {
    let result = ptr::read(dest);
    ptr::write(dest, src);
    result
  }
}
    \end{minted}
    \caption{interior unsafe in Rust's \code{replace} function}
    \label{lst:interiorunsafe}
    \vspace{-0.2cm}
\end{listing}

This leads to a design practice that interior unsafe functions should provide
the necessary checks that prevent the unsafe code from producing any undefined
behavior or memory safety bugs.
The callee in the safe world hence bears no responsibility to ensure safety.

\textbf{Interior Mutability.}
Mutating referenced data via an immutable reference is forbidden in Rust.
However, this is sometimes too restrictive for implementing efficient
algorithms or data structures.
For instance, a cache might be desirable for a read-only search data structure
to optimize lookup time. Nevertheless, updating the cache state requires
mutability for the cache, violating the read-only constraint.
Hence, a mechanism is needed for mutating data under a read-only variable.
The Rust standard library provides some special types that allow the user to
modify data even with read-only access, to address this issue.
This design pattern is known as \textit{Interior Mutability}.
\code{unsafe} operations are used to implement these types to bend Rust's usual
rules that govern mutation and borrowing.
These types ensure the borrowing rules are followed, i.e. one mutable borrower
at one time, and no mutable borrowers when read-only borrowers exist, at
runtime. A panic occurs whenever the runtime checks fail, stopping the program
to avoid safety issues. For example, \code{Mutex} in Rust provides interior
mutability. A lock is used to ensure that only one borrower of the inner data
exists at one time.
More precisely, when attempting to borrow data that has already been borrowed,
the \code{Mutex} enforces a busy wait until the data is released, thereby
allowing only one borrower at a time.
However, if a thread borrows the inner data of \code{Mutex} while it is already
borrowing it, \code{Mutex} will wait forever, i.e., result in a self-deadlock.

\textbf{Generics and Traits.}
In addition to the safety mechanisms, Rust also provides features for writing
code that operates on values of many different types. \code{Generic} allows
code to work with type parameters, reducing similar code that work with
different types.
For example, the vector type in Rust's standard library \code{std::vec::Vec}
is capable of holding an array of an arbitrary type.
Rust traits are properties or interfaces that can be implemented on types;
traits typically require the implementing type to supply function
implementations for its trait methods.
Additionally, combined with \code{Generic}, a trait can be treated as a
restriction on type specifications such as function arguments or struct fields.
The restriction is called a \textit{trait bound}.
For example, the \code{Clone} trait requires the implementing type
to provide implementations for its \code{clone} and \code{clone\_from} functions
to make copies of themselves.
A \code{Generic} function or type can use a trait bound to
require its type argument to implement \code{Clone},
so that it can invoke the \code{clone} function that the argument implements.

\textbf{Error Handling.}
Rust offers enum types \code{Result<T, E>} and \code{Option<T>} that have
variants to explicitly represent the state of error.
A \code{Result} type can be the enum variant \code{Ok(T)}, which denotes a
proper result with type \code{T}, or \code{Err(E)}, which represents an error
with reason of type \code{E}.
To simplify error handling,
Rust provides a convenient syntactic sugar,
the \code{?} operator.
When used on a \code{Result}, it retrieves the \code{T} from \code{Ok(T)}.
However, if the \code{Result} is \code{Err(E)}, the \code{Err} variant is
immediately returned from the enclosing function, propagating the error to the
caller.
When handling enum types, the program must handle all variants of the enum,
and not doing so results in a compilation error, this enforces the programmer
to handle all possible cases, including errors.
Similarly, \code{Option} can have the \code{Some(T)} variant, or the
\code{None} variant, which represents the state of not having a value.
These types prevent unexpected errors when accessing a potentially non-existing
value, or a potential error in the program.

\textbf{Copy and Drop Traits.}
Some traits in Rust have intrinsic meaning to the compiler. For example, the
\code{Drop} trait tells the compiler that a type has special freeing code, and
the \code{Drop} trait's \code{drop} function should be invoked when an instance
of the type goes out of scope. And the \code{Copy} trait, when implemented for
a type indicates that the type should be byte-by-byte copied when the
assignment (\code{=}) operator is used instead of Rust's typical semantic
of moving the ownership to the new variable. Interestingly, Rust forbids a type
from being \code{Drop} and \code{Copy} simultaneously, the designers of the
language observed that if a type requires special deallocating code (the
\code{drop} function), then it should also require a special copying function,
rather than just copying it byte-by-byte. For instance, a type that holds a
reference to the heap requires a \code{drop} function that frees the data
pointed to by the reference, copying the object of the type in a byte-by-byte
manner introduces risks of double-free, use-after-free, etc.

