\chapter{Evaluation}
\label{sec:eval}

We evaluated the performance of various application benchmarks
on a VM running on \rustsec{}, SeKVM, and mainline KVM.
We also tested the same
benchmarks on bare metal environment performances to establish a baseline
reference of the benchmark results. The workloads were run on the Raspberry
Pi 4 model B development board, with a Broadcom BCM2711, quad-core
Cortex-A72 (ARM v8) 64-bit SoC at 1.5GHz, 4GB of RAM, and a 1 GbE NIC device.

\rustsec{}, SeKVM, and the mainline KVM are all based on Linux 5.15.
QEMU v4.0.0 was used to start the virtual machines on Ubuntu 20.04. The guest
kernels also used Linux 5.15, and all kernels tested employed the same 
configuration. We requested the authors of~\cite{hypsec} and got a patch for
the Linux guest kernel to enable virtio.
\code{rustc} version 1.68.0-nightly was used to compile \rustcore{},
while clang 15.0.0 was used to compile the remaining components of
\rustsec{}, SeKVM, and the mainline KVM.
2 physical CPUs and 1 GB of RAM is configured for the bare
metal setup, and each VM is equipped with 2 virtual CPUs , and 1 GB of RAM.

We ran the benchmarks listed in \autoref{tab:benchmark} in VMs on
\rustsec{}, SeKVM, and the mainline KVM. \autoref{fig:eval} shows the normalized
results. In \autoref{fig:eval} we normalized the results to bare-metal
performance. 1.00 refers to no virtualization overhead, and
a higher value means higher overhead. The performance on real application
workloads show modest overhead overall for \rustsec{} compared to SeKVM and
mainline KVM.

In the \code{TCP\_MAERTS} benchmark, it can be observed that mainline KVM,
SeKVM, and \rustsec{} all outperformed the bare-metal setup. This is caused by
the four experimental setups saturating the 1GbE NIC on the Raspberry Pi 4
model B. Additionally, experimental error had a more noticeable impact during
the measurement of the bare-metal setup, making its performance the worst.

For \code{TCP\_RR} and the YCSB-Redis benchmarks, \rustsec{} experienced higher
overhead difference compared to mainline KVM at around 8\% and 14\%,
respectively.
Performance of the bare-metal setup of these two benchmarks
are roughly twice as good as the VMs, amplifying the difference between mainline
KVM and \rustsec{} when plotting \autoref{fig:eval}.
%In fact, if the overhead are plotted by normalizing against the
%performance of mainline KVM (\autoref{fig:eval2}), all benchmarks run on
%\rustsec{} experience an overhead less than 10\% compared to mainline KVM.
In fact, when the performance is normalized against
mainline KVM (\autoref{fig:eval2}), all benchmarks executed on \rustsec{}
demonstrate an overhead of less than 10\% compared to mainline KVM.

%\rustsec{} performs nearly as well as mainline KVM in
%CPU bound benchmarks and bulk data network performance benchmarks
%(\code{TCP\_MAERTS}, \code{TCP\_STREAM}) since
%the workloads require minimal to no VM exits.
%The discrepancy arises in \code{TCP\_RR}, Apache, Memcached,
%and YCSB-Redis, which involve a higher number of VM exits due to their frequent
%small network transmissions. Both SeKVM and \rustsec{} execute additional logic
%in EL2 to ensure VM data confidentiality and integrity, resulting in increased
%overhead in VM exits compared to mainline KVM.

%The worst overhead for \rustsec{} compared to mainline KVM occurs for the
%YCSB-Redis benchmark at around 14\%.
%Various system noise factors e.g. caches, kernel thread wakeups, and dynamic
%voltage frequency scaling might also come into play.

\begin{table}
\centering
\footnotesize
\begin{tabular}{ |p{0.2\linewidth}|p{0.7\linewidth}| }
 \hline
 \small{\textbf{Name}} & \small{\textbf{Description}} \\
 \hline
 \small{Kernbench} & \small{Compilation of the Linux 6.0 kernel using \code{tinyconfig} for Arm with GCC 9.4.0.} \\
 \hline
 \small{Hackbench} & \small{\code{hackbench}~\cite{hackbench} using Unix domain sockets and 50 process groups running in 50 loops.} \\
 \hline
 \small{Netperf} & \small{\code{netperf}~\cite{netperf} v2.6.0 running the netserver on the server and the client with its default parameters in three modes: TCP\_STREAM (throughput), TCP\_MAERTS (throughput), and TCP\_RR (latency).} \\
 \hline
 \small{Apache} & \small{\code{Apache} v2.4.41 Web server running \code{ApacheBench}~\cite{ab} v2.3 on the remote client, which measures the number of handled requests per second when serving the 41 KB index.html file of the GCC 4.4 manual using 100 concurrent requests.} \\
 \hline
 \small{Memcached} & \small{\code{memcached} v1.5.22 using the \code{memtier}~\cite{memtier} benchmark v1.2.3 with its default parameters.} \\
 \hline
 \small{YCSB-Redis} & \small{\code{redis} v7.0.11 using the \code{YCSB}~\cite{YCSB, YCSB2} benchmark v0.17.0 with its default parameters.} \\
 \hline
\end{tabular}
\vspace{0.3cm}
\caption{Application Benchmarks}
\label{tab:benchmark}
\end{table}

\begin{figure}[hbtp]
    \includegraphics[scale=0.45]{figures/eval.pdf}
    \caption{Application Benchmark Performance: Overhead normalized to the bare-metal setup}
    \label{fig:eval}
\end{figure}

\begin{figure}[hbtp]
    \includegraphics[scale=0.45]{figures/eval2.pdf}
    \caption{Application Benchmark Performance: Overhead normalized to mainline KVM}
    \label{fig:eval2}
\end{figure}
